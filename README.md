## MUTE: A Multimodal Dataset for Detecting Hateful Memes

**Author:** Eftekhar Hossain, Omar Sharif, and Mohammed Moshiul Hoque

**Venue:** AACL-IJCNLP, Student Research Workshop (AACL-2022)   

 [**Paper Link:**](https://aclanthology.org/2022.aacl-srw.5/)

 [**Dataset**](https://drive.google.com/file/d/1ozTFUM7q27g7uckhPWUiQFwhROCiEUAc/view?usp=sharing)


 ## Citation
If you use our dataset, models or code, please cite the following paper:
```
@inproceedings{hossain-etal-2022-mute,
    title = "{MUTE}: A Multimodal Dataset for Detecting Hateful Memes",
    author = "Hossain, Eftekhar  and
      Sharif, Omar  and
      Hoque, Mohammed Moshiul",
    booktitle = "Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing: Student Research Workshop",
    month = nov,
    year = "2022",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.aacl-srw.5",
    pages = "32--39",
    abstract = "The exponential surge of social media has enabled information propagation at an unprecedented rate. However, it also led to the generation of a vast amount of malign content, such as hateful memes. To eradicate the detrimental impact of this content, over the last few years hateful memes detection problem has grabbed the attention of researchers. However, most past studies were conducted primarily for English memes, while memes on resource constraint languages (i.e., Bengali) are under-studied. Moreover, current research considers memes with a caption written in monolingual (either English or Bengali) form. However, memes might have code-mixed captions (English+Bangla), and the existing models can not provide accurate inference in such cases. Therefore, to facilitate research in this arena, this paper introduces a multimodal hate speech dataset (named MUTE) consisting of 4158 memes having Bengali and code-mixed captions. A detailed annotation guideline is provided to aid the dataset creation in other resource constraint languages. Additionally, extensive experiments have been carried out on MUTE, considering the only visual, only textual, and both modalities. The result demonstrates that joint evaluation of visual and textual features significantly improves ({\mbox{$\approx$}} 3{\%}) the hateful memes classification compared to the unimodal evaluation.",
}
```
